{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import coloredlogs\n",
    "from FAdo.conversions import *\n",
    "\n",
    "from utils.data_loader import *\n",
    "from utils.heuristics import *\n",
    "\n",
    "from alpha_zero.Coach import Coach\n",
    "from alpha_zero.MCTS import MCTS\n",
    "from alpha_zero.utils import *\n",
    "from alpha_zero.state_elimination.StateEliminationGame import StateEliminationGame as Game\n",
    "from alpha_zero.state_elimination.pytorch.NNet import NNetWrapper as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)\n",
    "coloredlogs.install(level='INFO')\n",
    "args = dotdict({\n",
    "    'numIters': 1000,\n",
    "    # Number of complete self-play games to simulate during a new iteration.\n",
    "    'numEps': 100,\n",
    "    'tempThreshold': 0,        # temperature hyperparameters\n",
    "    # During arena playoff, new neural net will be accepted if threshold or more of games are won.\n",
    "    'updateThreshold': 0.6,\n",
    "    # Number of game examples to train the neural networks.\n",
    "    'maxlenOfQueue': 200000,\n",
    "    'numMCTSSims': 25,          # Number of games moves for MCTS to simulate.\n",
    "    # Number of games to play during arena play to determine if new net will be accepted.\n",
    "    'arenaCompare': 40,\n",
    "    'cpuct': 1,\n",
    "    'checkpoint': './alpha_zero/models/',\n",
    "    'load_model': True,\n",
    "    'load_folder_file': ('./alpha_zero/models/', 'best.pth.tar'),\n",
    "    'numItersForTrainExamplesHistory': 20,\n",
    "})\n",
    "min_n = 3\n",
    "max_n = 6\n",
    "n_range = max_n - min_n + 1\n",
    "alphabet = [2]\n",
    "density = [0.2]\n",
    "sample_size = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_heuristics():\n",
    "    if os.path.isfile('./result/heuristics_experiment_result.pkl'):\n",
    "        with open('./result/heuristics_experiment_result.pkl', 'rb') as fp:\n",
    "            exp = load(fp)\n",
    "            return exp\n",
    "    else:\n",
    "        data = load_data()\n",
    "        exp = [[[[[0, 0] for d in range(len(density))] for k in range(\n",
    "            len(alphabet))] for n in range(n_range)] for c in range(6)]\n",
    "        for n in range(n_range):\n",
    "            for k in range(len(alphabet)):\n",
    "                for d in range(len(density)):\n",
    "                    for i in range(sample_size):\n",
    "                        random.seed(i)\n",
    "                        print('n' + str(n + min_n) + 'k' + ('2' if not k else ('5' if k == 1 else '10')) + (\n",
    "                            's' if not d else 'd') + '\\'s ' + str(i + 1) + ' sample')\n",
    "                        # eliminate_randomly\n",
    "                        gfa = data[n][k][d][i].dup()\n",
    "                        start_time = time.time()\n",
    "                        result = eliminate_randomly(gfa)\n",
    "                        end_time = time.time()\n",
    "                        result_time = end_time - start_time\n",
    "                        result_size = result.treeLength()\n",
    "                        exp[0][n][k][d][0] += result_time\n",
    "                        exp[0][n][k][d][1] += result_size\n",
    "\n",
    "                        # decompose with eliminate_randomly\n",
    "                        gfa = data[n][k][d][i].dup()\n",
    "                        start_time = time.time()\n",
    "                        result = decompose(gfa, False, False)\n",
    "                        end_time = time.time()\n",
    "                        result_time = end_time - start_time\n",
    "                        result_size = result.treeLength()\n",
    "                        exp[1][n][k][d][0] += result_time\n",
    "                        exp[1][n][k][d][1] += result_size\n",
    "\n",
    "                        # eliminate_by_state_weight_heuristic\n",
    "                        gfa = data[n][k][d][i].dup()\n",
    "                        start_time = time.time()\n",
    "                        result = eliminate_by_state_weight_heuristic(gfa)\n",
    "                        end_time = time.time()\n",
    "                        result_time = end_time - start_time\n",
    "                        result_size = result.treeLength()\n",
    "                        exp[2][n][k][d][0] += result_time\n",
    "                        exp[2][n][k][d][1] += result_size\n",
    "\n",
    "                        # decompose + eliminate_by_state_weight_heuristic\n",
    "                        gfa = data[n][k][d][i].dup()\n",
    "                        start_time = time.time()\n",
    "                        result = decompose(gfa, True, False)\n",
    "                        end_time = time.time()\n",
    "                        result_time = end_time - start_time\n",
    "                        result_size = result.treeLength()\n",
    "                        exp[3][n][k][d][0] += result_time\n",
    "                        exp[3][n][k][d][1] += result_size\n",
    "\n",
    "                        # eliminate_by_repeated_state_weight_heuristic\n",
    "                        gfa = data[n][k][d][i].dup()\n",
    "                        start_time = time.time()\n",
    "                        result = eliminate_by_repeated_state_weight_heuristic(\n",
    "                            gfa)\n",
    "                        end_time = time.time()\n",
    "                        result_time = end_time - start_time\n",
    "                        result_size = result.treeLength()\n",
    "                        exp[4][n][k][d][0] += result_time\n",
    "                        exp[4][n][k][d][1] += result_size\n",
    "\n",
    "                        # decompose + eliminate_by_repeated_state_weight_heuristic\n",
    "                        gfa = data[n][k][d][i].dup()\n",
    "                        start_time = time.time()\n",
    "                        result = decompose(gfa, True, True)\n",
    "                        end_time = time.time()\n",
    "                        result_time = end_time - start_time\n",
    "                        result_size = result.treeLength()\n",
    "                        exp[5][n][k][d][0] += result_time\n",
    "                        exp[5][n][k][d][1] += result_size\n",
    "        with open('./result/heuristics_experiment_result.pkl', 'wb') as fp:\n",
    "            dump(exp, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n3k2s's 1 sample\n",
      "n3k2s's 2 sample\n",
      "n3k2s's 3 sample\n",
      "n3k2s's 4 sample\n",
      "n3k2s's 5 sample\n",
      "n3k2s's 6 sample\n",
      "n3k2s's 7 sample\n",
      "n3k2s's 8 sample\n",
      "n3k2s's 9 sample\n",
      "n3k2s's 10 sample\n",
      "n3k2s's 11 sample\n",
      "n3k2s's 12 sample\n",
      "n3k2s's 13 sample\n",
      "n3k2s's 14 sample\n",
      "n3k2s's 15 sample\n",
      "n3k2s's 16 sample\n",
      "n3k2s's 17 sample\n",
      "n3k2s's 18 sample\n",
      "n3k2s's 19 sample\n",
      "n3k2s's 20 sample\n",
      "n3k2s's 21 sample\n",
      "n3k2s's 22 sample\n",
      "n3k2s's 23 sample\n",
      "n3k2s's 24 sample\n",
      "n3k2s's 25 sample\n",
      "n3k2s's 26 sample\n",
      "n3k2s's 27 sample\n",
      "n3k2s's 28 sample\n",
      "n3k2s's 29 sample\n",
      "n3k2s's 30 sample\n",
      "n4k2s's 1 sample\n",
      "n4k2s's 2 sample\n",
      "n4k2s's 3 sample\n",
      "n4k2s's 4 sample\n",
      "n4k2s's 5 sample\n",
      "n4k2s's 6 sample\n",
      "n4k2s's 7 sample\n",
      "n4k2s's 8 sample\n",
      "n4k2s's 9 sample\n",
      "n4k2s's 10 sample\n",
      "n4k2s's 11 sample\n",
      "n4k2s's 12 sample\n",
      "n4k2s's 13 sample\n",
      "n4k2s's 14 sample\n",
      "n4k2s's 15 sample\n",
      "n4k2s's 16 sample\n",
      "n4k2s's 17 sample\n",
      "n4k2s's 18 sample\n",
      "n4k2s's 19 sample\n",
      "n4k2s's 20 sample\n",
      "n4k2s's 21 sample\n",
      "n4k2s's 22 sample\n",
      "n4k2s's 23 sample\n",
      "n4k2s's 24 sample\n",
      "n4k2s's 25 sample\n",
      "n4k2s's 26 sample\n",
      "n4k2s's 27 sample\n",
      "n4k2s's 28 sample\n",
      "n4k2s's 29 sample\n",
      "n4k2s's 30 sample\n",
      "n5k2s's 1 sample\n",
      "n5k2s's 2 sample\n",
      "n5k2s's 3 sample\n",
      "n5k2s's 4 sample\n",
      "n5k2s's 5 sample\n",
      "n5k2s's 6 sample\n",
      "n5k2s's 7 sample\n",
      "n5k2s's 8 sample\n",
      "n5k2s's 9 sample\n",
      "n5k2s's 10 sample\n",
      "n5k2s's 11 sample\n",
      "n5k2s's 12 sample\n",
      "n5k2s's 13 sample\n",
      "n5k2s's 14 sample\n",
      "n5k2s's 15 sample\n",
      "n5k2s's 16 sample\n",
      "n5k2s's 17 sample\n",
      "n5k2s's 18 sample\n",
      "n5k2s's 19 sample\n",
      "n5k2s's 20 sample\n",
      "n5k2s's 21 sample\n",
      "n5k2s's 22 sample\n",
      "n5k2s's 23 sample\n",
      "n5k2s's 24 sample\n",
      "n5k2s's 25 sample\n",
      "n5k2s's 26 sample\n",
      "n5k2s's 27 sample\n",
      "n5k2s's 28 sample\n",
      "n5k2s's 29 sample\n",
      "n5k2s's 30 sample\n",
      "n6k2s's 1 sample\n",
      "n6k2s's 2 sample\n",
      "n6k2s's 3 sample\n",
      "n6k2s's 4 sample\n",
      "n6k2s's 5 sample\n",
      "n6k2s's 6 sample\n",
      "n6k2s's 7 sample\n",
      "n6k2s's 8 sample\n",
      "n6k2s's 9 sample\n",
      "n6k2s's 10 sample\n",
      "n6k2s's 11 sample\n",
      "n6k2s's 12 sample\n",
      "n6k2s's 13 sample\n",
      "n6k2s's 14 sample\n",
      "n6k2s's 15 sample\n",
      "n6k2s's 16 sample\n",
      "n6k2s's 17 sample\n",
      "n6k2s's 18 sample\n",
      "n6k2s's 19 sample\n",
      "n6k2s's 20 sample\n",
      "n6k2s's 21 sample\n",
      "n6k2s's 22 sample\n",
      "n6k2s's 23 sample\n",
      "n6k2s's 24 sample\n",
      "n6k2s's 25 sample\n",
      "n6k2s's 26 sample\n",
      "n6k2s's 27 sample\n",
      "n6k2s's 28 sample\n",
      "n6k2s's 29 sample\n",
      "n6k2s's 30 sample\n"
     ]
    }
   ],
   "source": [
    "exp = test_heuristics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 19:39:49 ksk numexpr.utils[1335862] INFO Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2023-03-15 19:39:49 ksk numexpr.utils[1335862] INFO NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_alpha_zero():\n",
    "    if not os.path.isfile('./result/alpha_zero_experiment_result.pkl'):\n",
    "        with open('./result/alpha_zero_experiment_result.pkl', 'rb') as fp:\n",
    "            exp = load(fp)\n",
    "        with open('./result/c7.csv', 'w', newline='') as fp:\n",
    "            writer = csv.writer(fp)\n",
    "            for n in range(5 - 3, 11 - 3):\n",
    "                size_value = exp[n][1][0][1] / 100\n",
    "                writer.writerow([size_value])\n",
    "    else:\n",
    "        data = load_data()\n",
    "        exp = [[[[0, 0] for d in range(len(density))] for k in range(\n",
    "            len(alphabet))] for n in range(n_range)]\n",
    "        g = Game()\n",
    "        nnet = nn(g)\n",
    "        mcts = MCTS(g, nnet, args)\n",
    "        def player(x): return np.argmax(mcts.getActionProb(x, temp=0))\n",
    "        curPlayer = 1\n",
    "        if args.load_model:\n",
    "            nnet.load_checkpoint(args.checkpoint, args.load_folder_file[1])\n",
    "        else:\n",
    "            print(\"Can't test without pre-trained model\")\n",
    "            exit()\n",
    "        for n in range(n_range):\n",
    "            for k in range(len(alphabet)):\n",
    "                for d in range(len(density)):\n",
    "                    for i in range(sample_size):\n",
    "                        #print('n' + str(n + min_n) + 'k' + ('2' if not k else ('5' if k == 1 else '10')) + (\n",
    "                        #    's' if not d else 'd') + '\\'s ' + str(i + 1) + ' sample')\n",
    "                        gfa = data[n][k][d][i].dup()\n",
    "                        board = g.getInitBoard(\n",
    "                            gfa, n + min_n, alphabet[k], density[d])\n",
    "                        order = []\n",
    "                        start_time = time.time()\n",
    "                        while g.getGameEnded(board, curPlayer) == -1:\n",
    "                            action = player(\n",
    "                                g.getCanonicalForm(board, curPlayer))\n",
    "                            valids = g.getValidMoves(\n",
    "                                g.getCanonicalForm(board, curPlayer), 1)\n",
    "                            if valids[action] == 0:\n",
    "                                assert valids[action] > 0\n",
    "                            board, curPlayer = g.getNextState(\n",
    "                                board, curPlayer, action)\n",
    "                            order.append(action)\n",
    "                            \n",
    "                        result = g.gfaToBoard(board)[0][n + min_n + 1].treeLength()\n",
    "                        end_time = time.time()\n",
    "                        gfa.eliminateAll(order)\n",
    "                        '''\n",
    "                        if (result != gfa.delta[0][n + min_n + 1].treeLength()):\n",
    "                            print('order', order)\n",
    "                            print('result length', result)\n",
    "                            print('valid length',\n",
    "                                  gfa.delta[0][n + min_n + 1].treeLength())\n",
    "                            print('Something is wrong')\n",
    "                            exit()\n",
    "                        '''\n",
    "                        result_time = end_time - start_time\n",
    "                        exp[n][k][d][0] += result_time\n",
    "                        exp[n][k][d][1] += result\n",
    "        with open('./result/alpha_zero_experiment_result.pkl', 'wb') as fp:\n",
    "            dump(exp, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_alpha_zero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./result/alpha_zero_experiment_result.pkl', 'rb') as fp:\n",
    "    exp_alpha = load(fp)\n",
    "\n",
    "with open('./result/heuristics_experiment_result.pkl', 'rb') as fp:\n",
    "    exp_heuristic = load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0.016735553741455078, 372.0],\n",
       "  [0.018989086151123047, 752.0],\n",
       "  [0.026637554168701172, 1839.0],\n",
       "  [0.0336604118347168, 3093.0]],\n",
       " [[1.4725992679595947, 217.0],\n",
       "  [4.289000034332275, 587.0],\n",
       "  [13.468000173568726, 2179.0],\n",
       "  [35.0204656124115, 5617.0]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(exp_heuristic[5][:4])[:, 0, 0].tolist(), np.array(exp_alpha[:4])[:, 0, 0].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38-6D1UywTv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
