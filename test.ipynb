{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import coloredlogs\n",
    "from FAdo.conversions import *\n",
    "\n",
    "from utils.data_loader import *\n",
    "from utils.heuristics import *\n",
    "\n",
    "from alpha_zero.Coach import Coach\n",
    "from alpha_zero.MCTS import MCTS\n",
    "from alpha_zero.utils import *\n",
    "from alpha_zero.state_elimination.StateEliminationGame import StateEliminationGame as Game\n",
    "from alpha_zero.state_elimination.pytorch.NNet import NNetWrapper as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)\n",
    "coloredlogs.install(level='INFO')\n",
    "args = dotdict({\n",
    "    'numIters': 1000,\n",
    "    # Number of complete self-play games to simulate during a new iteration.\n",
    "    'numEps': 100,\n",
    "    'tempThreshold': 0,        # temperature hyperparameters\n",
    "    # During arena playoff, new neural net will be accepted if threshold or more of games are won.\n",
    "    'updateThreshold': 0.6,\n",
    "    # Number of game examples to train the neural networks.\n",
    "    'maxlenOfQueue': 200000,\n",
    "    'numMCTSSims': 25,          # Number of games moves for MCTS to simulate.\n",
    "    # Number of games to play during arena play to determine if new net will be accepted.\n",
    "    'arenaCompare': 40,\n",
    "    'cpuct': 1,\n",
    "    'checkpoint': './alpha_zero/models/',\n",
    "    'load_model': False,\n",
    "    'load_folder_file': ('./alpha_zero/models/', 'best.pth.tar'),\n",
    "    'numItersForTrainExamplesHistory': 20,\n",
    "})\n",
    "min_n = 3\n",
    "max_n = 7\n",
    "n_range = max_n - min_n + 1\n",
    "alphabet = [2, 5, 10]\n",
    "density = [0.2, 0.5]\n",
    "sample_size = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_heuristics():\n",
    "    if os.path.isfile('./result/heuristics_experiment_result.pkl'):\n",
    "        with open('./result/heuristics_experiment_result.pkl', 'rb') as fp:\n",
    "            exp = load(fp)\n",
    "    else:\n",
    "        data = load_data()\n",
    "        exp = [[[[[0, 0] for d in range(len(density))] for k in range(\n",
    "            len(alphabet))] for n in range(n_range)] for c in range(6)]\n",
    "        for n in range(n_range):\n",
    "            for k in range(len(alphabet)):\n",
    "                for d in range(len(density)):\n",
    "                    for i in range(sample_size):\n",
    "                        random.seed(i)\n",
    "                        print('n' + str(n + min_n) + 'k' + ('2' if not k else ('5' if k == 1 else '10')) + (\n",
    "                            's' if not d else 'd') + '\\'s ' + str(i + 1) + ' sample')\n",
    "                        # eliminate_randomly\n",
    "                        gfa = data[n][k][d][i].dup()\n",
    "                        start_time = time.time()\n",
    "                        result = eliminate_randomly(gfa)\n",
    "                        end_time = time.time()\n",
    "                        result_time = end_time - start_time\n",
    "                        result_size = result.treeLength()\n",
    "                        exp[0][n][k][d][0] += result_time\n",
    "                        exp[0][n][k][d][1] += result_size\n",
    "\n",
    "                        # decompose with eliminate_randomly\n",
    "                        gfa = data[n][k][d][i].dup()\n",
    "                        start_time = time.time()\n",
    "                        result = decompose(gfa, False, False)\n",
    "                        end_time = time.time()\n",
    "                        result_time = end_time - start_time\n",
    "                        result_size = result.treeLength()\n",
    "                        exp[1][n][k][d][0] += result_time\n",
    "                        exp[1][n][k][d][1] += result_size\n",
    "\n",
    "                        # eliminate_by_state_weight_heuristic\n",
    "                        gfa = data[n][k][d][i].dup()\n",
    "                        start_time = time.time()\n",
    "                        result = eliminate_by_state_weight_heuristic(gfa)\n",
    "                        end_time = time.time()\n",
    "                        result_time = end_time - start_time\n",
    "                        result_size = result.treeLength()\n",
    "                        exp[2][n][k][d][0] += result_time\n",
    "                        exp[2][n][k][d][1] += result_size\n",
    "\n",
    "                        # decompose + eliminate_by_state_weight_heuristic\n",
    "                        gfa = data[n][k][d][i].dup()\n",
    "                        start_time = time.time()\n",
    "                        result = decompose(gfa, True, False)\n",
    "                        end_time = time.time()\n",
    "                        result_time = end_time - start_time\n",
    "                        result_size = result.treeLength()\n",
    "                        exp[3][n][k][d][0] += result_time\n",
    "                        exp[3][n][k][d][1] += result_size\n",
    "\n",
    "                        # eliminate_by_repeated_state_weight_heuristic\n",
    "                        gfa = data[n][k][d][i].dup()\n",
    "                        start_time = time.time()\n",
    "                        result = eliminate_by_repeated_state_weight_heuristic(\n",
    "                            gfa)\n",
    "                        end_time = time.time()\n",
    "                        result_time = end_time - start_time\n",
    "                        result_size = result.treeLength()\n",
    "                        exp[4][n][k][d][0] += result_time\n",
    "                        exp[4][n][k][d][1] += result_size\n",
    "\n",
    "                        # decompose + eliminate_by_repeated_state_weight_heuristic\n",
    "                        gfa = data[n][k][d][i].dup()\n",
    "                        start_time = time.time()\n",
    "                        result = decompose(gfa, True, True)\n",
    "                        end_time = time.time()\n",
    "                        result_time = end_time - start_time\n",
    "                        result_size = result.treeLength()\n",
    "                        exp[5][n][k][d][0] += result_time\n",
    "                        exp[5][n][k][d][1] += result_size\n",
    "        with open('./result/heuristics_experiment_result.pkl', 'wb') as fp:\n",
    "            dump(exp, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n3k2s's 1 sample\n",
      "n3k2s's 2 sample\n",
      "n3k2s's 3 sample\n",
      "n3k2s's 4 sample\n",
      "n3k2s's 5 sample\n",
      "n3k2s's 6 sample\n",
      "n3k2s's 7 sample\n",
      "n3k2s's 8 sample\n",
      "n3k2s's 9 sample\n",
      "n3k2s's 10 sample\n",
      "n3k2d's 1 sample\n",
      "n3k2d's 2 sample\n",
      "n3k2d's 3 sample\n",
      "n3k2d's 4 sample\n",
      "n3k2d's 5 sample\n",
      "n3k2d's 6 sample\n",
      "n3k2d's 7 sample\n",
      "n3k2d's 8 sample\n",
      "n3k2d's 9 sample\n",
      "n3k2d's 10 sample\n",
      "n3k5s's 1 sample\n",
      "n3k5s's 2 sample\n",
      "n3k5s's 3 sample\n",
      "n3k5s's 4 sample\n",
      "n3k5s's 5 sample\n",
      "n3k5s's 6 sample\n",
      "n3k5s's 7 sample\n",
      "n3k5s's 8 sample\n",
      "n3k5s's 9 sample\n",
      "n3k5s's 10 sample\n",
      "n3k5d's 1 sample\n",
      "n3k5d's 2 sample\n",
      "n3k5d's 3 sample\n",
      "n3k5d's 4 sample\n",
      "n3k5d's 5 sample\n",
      "n3k5d's 6 sample\n",
      "n3k5d's 7 sample\n",
      "n3k5d's 8 sample\n",
      "n3k5d's 9 sample\n",
      "n3k5d's 10 sample\n",
      "n3k10s's 1 sample\n",
      "n3k10s's 2 sample\n",
      "n3k10s's 3 sample\n",
      "n3k10s's 4 sample\n",
      "n3k10s's 5 sample\n",
      "n3k10s's 6 sample\n",
      "n3k10s's 7 sample\n",
      "n3k10s's 8 sample\n",
      "n3k10s's 9 sample\n",
      "n3k10s's 10 sample\n",
      "n3k10d's 1 sample\n",
      "n3k10d's 2 sample\n",
      "n3k10d's 3 sample\n",
      "n3k10d's 4 sample\n",
      "n3k10d's 5 sample\n",
      "n3k10d's 6 sample\n",
      "n3k10d's 7 sample\n",
      "n3k10d's 8 sample\n",
      "n3k10d's 9 sample\n",
      "n3k10d's 10 sample\n",
      "n4k2s's 1 sample\n",
      "n4k2s's 2 sample\n",
      "n4k2s's 3 sample\n",
      "n4k2s's 4 sample\n",
      "n4k2s's 5 sample\n",
      "n4k2s's 6 sample\n",
      "n4k2s's 7 sample\n",
      "n4k2s's 8 sample\n",
      "n4k2s's 9 sample\n",
      "n4k2s's 10 sample\n",
      "n4k2d's 1 sample\n",
      "n4k2d's 2 sample\n",
      "n4k2d's 3 sample\n",
      "n4k2d's 4 sample\n",
      "n4k2d's 5 sample\n",
      "n4k2d's 6 sample\n",
      "n4k2d's 7 sample\n",
      "n4k2d's 8 sample\n",
      "n4k2d's 9 sample\n",
      "n4k2d's 10 sample\n",
      "n4k5s's 1 sample\n",
      "n4k5s's 2 sample\n",
      "n4k5s's 3 sample\n",
      "n4k5s's 4 sample\n",
      "n4k5s's 5 sample\n",
      "n4k5s's 6 sample\n",
      "n4k5s's 7 sample\n",
      "n4k5s's 8 sample\n",
      "n4k5s's 9 sample\n",
      "n4k5s's 10 sample\n",
      "n4k5d's 1 sample\n",
      "n4k5d's 2 sample\n",
      "n4k5d's 3 sample\n",
      "n4k5d's 4 sample\n",
      "n4k5d's 5 sample\n",
      "n4k5d's 6 sample\n",
      "n4k5d's 7 sample\n",
      "n4k5d's 8 sample\n",
      "n4k5d's 9 sample\n",
      "n4k5d's 10 sample\n",
      "n4k10s's 1 sample\n",
      "n4k10s's 2 sample\n",
      "n4k10s's 3 sample\n",
      "n4k10s's 4 sample\n",
      "n4k10s's 5 sample\n",
      "n4k10s's 6 sample\n",
      "n4k10s's 7 sample\n",
      "n4k10s's 8 sample\n",
      "n4k10s's 9 sample\n",
      "n4k10s's 10 sample\n",
      "n4k10d's 1 sample\n",
      "n4k10d's 2 sample\n",
      "n4k10d's 3 sample\n",
      "n4k10d's 4 sample\n",
      "n4k10d's 5 sample\n",
      "n4k10d's 6 sample\n",
      "n4k10d's 7 sample\n",
      "n4k10d's 8 sample\n",
      "n4k10d's 9 sample\n",
      "n4k10d's 10 sample\n",
      "n5k2s's 1 sample\n",
      "n5k2s's 2 sample\n",
      "n5k2s's 3 sample\n",
      "n5k2s's 4 sample\n",
      "n5k2s's 5 sample\n",
      "n5k2s's 6 sample\n",
      "n5k2s's 7 sample\n",
      "n5k2s's 8 sample\n",
      "n5k2s's 9 sample\n",
      "n5k2s's 10 sample\n",
      "n5k2d's 1 sample\n",
      "n5k2d's 2 sample\n",
      "n5k2d's 3 sample\n",
      "n5k2d's 4 sample\n",
      "n5k2d's 5 sample\n",
      "n5k2d's 6 sample\n",
      "n5k2d's 7 sample\n",
      "n5k2d's 8 sample\n",
      "n5k2d's 9 sample\n",
      "n5k2d's 10 sample\n",
      "n5k5s's 1 sample\n",
      "n5k5s's 2 sample\n",
      "n5k5s's 3 sample\n",
      "n5k5s's 4 sample\n",
      "n5k5s's 5 sample\n",
      "n5k5s's 6 sample\n",
      "n5k5s's 7 sample\n",
      "n5k5s's 8 sample\n",
      "n5k5s's 9 sample\n",
      "n5k5s's 10 sample\n",
      "n5k5d's 1 sample\n",
      "n5k5d's 2 sample\n",
      "n5k5d's 3 sample\n",
      "n5k5d's 4 sample\n",
      "n5k5d's 5 sample\n",
      "n5k5d's 6 sample\n",
      "n5k5d's 7 sample\n",
      "n5k5d's 8 sample\n",
      "n5k5d's 9 sample\n",
      "n5k5d's 10 sample\n",
      "n5k10s's 1 sample\n",
      "n5k10s's 2 sample\n",
      "n5k10s's 3 sample\n",
      "n5k10s's 4 sample\n",
      "n5k10s's 5 sample\n",
      "n5k10s's 6 sample\n",
      "n5k10s's 7 sample\n",
      "n5k10s's 8 sample\n",
      "n5k10s's 9 sample\n",
      "n5k10s's 10 sample\n",
      "n5k10d's 1 sample\n",
      "n5k10d's 2 sample\n",
      "n5k10d's 3 sample\n",
      "n5k10d's 4 sample\n",
      "n5k10d's 5 sample\n",
      "n5k10d's 6 sample\n",
      "n5k10d's 7 sample\n",
      "n5k10d's 8 sample\n",
      "n5k10d's 9 sample\n",
      "n5k10d's 10 sample\n",
      "n6k2s's 1 sample\n",
      "n6k2s's 2 sample\n",
      "n6k2s's 3 sample\n",
      "n6k2s's 4 sample\n",
      "n6k2s's 5 sample\n",
      "n6k2s's 6 sample\n",
      "n6k2s's 7 sample\n",
      "n6k2s's 8 sample\n",
      "n6k2s's 9 sample\n",
      "n6k2s's 10 sample\n",
      "n6k2d's 1 sample\n",
      "n6k2d's 2 sample\n",
      "n6k2d's 3 sample\n",
      "n6k2d's 4 sample\n",
      "n6k2d's 5 sample\n",
      "n6k2d's 6 sample\n",
      "n6k2d's 7 sample\n",
      "n6k2d's 8 sample\n",
      "n6k2d's 9 sample\n",
      "n6k2d's 10 sample\n",
      "n6k5s's 1 sample\n",
      "n6k5s's 2 sample\n",
      "n6k5s's 3 sample\n",
      "n6k5s's 4 sample\n",
      "n6k5s's 5 sample\n",
      "n6k5s's 6 sample\n",
      "n6k5s's 7 sample\n",
      "n6k5s's 8 sample\n",
      "n6k5s's 9 sample\n",
      "n6k5s's 10 sample\n",
      "n6k5d's 1 sample\n",
      "n6k5d's 2 sample\n",
      "n6k5d's 3 sample\n",
      "n6k5d's 4 sample\n",
      "n6k5d's 5 sample\n",
      "n6k5d's 6 sample\n",
      "n6k5d's 7 sample\n",
      "n6k5d's 8 sample\n",
      "n6k5d's 9 sample\n",
      "n6k5d's 10 sample\n",
      "n6k10s's 1 sample\n",
      "n6k10s's 2 sample\n",
      "n6k10s's 3 sample\n",
      "n6k10s's 4 sample\n",
      "n6k10s's 5 sample\n",
      "n6k10s's 6 sample\n",
      "n6k10s's 7 sample\n",
      "n6k10s's 8 sample\n",
      "n6k10s's 9 sample\n",
      "n6k10s's 10 sample\n",
      "n6k10d's 1 sample\n",
      "n6k10d's 2 sample\n",
      "n6k10d's 3 sample\n",
      "n6k10d's 4 sample\n",
      "n6k10d's 5 sample\n",
      "n6k10d's 6 sample\n",
      "n6k10d's 7 sample\n",
      "n6k10d's 8 sample\n",
      "n6k10d's 9 sample\n",
      "n6k10d's 10 sample\n",
      "n7k2s's 1 sample\n",
      "n7k2s's 2 sample\n",
      "n7k2s's 3 sample\n",
      "n7k2s's 4 sample\n",
      "n7k2s's 5 sample\n",
      "n7k2s's 6 sample\n",
      "n7k2s's 7 sample\n",
      "n7k2s's 8 sample\n",
      "n7k2s's 9 sample\n",
      "n7k2s's 10 sample\n",
      "n7k2d's 1 sample\n",
      "n7k2d's 2 sample\n",
      "n7k2d's 3 sample\n",
      "n7k2d's 4 sample\n",
      "n7k2d's 5 sample\n",
      "n7k2d's 6 sample\n",
      "n7k2d's 7 sample\n",
      "n7k2d's 8 sample\n",
      "n7k2d's 9 sample\n",
      "n7k2d's 10 sample\n",
      "n7k5s's 1 sample\n",
      "n7k5s's 2 sample\n",
      "n7k5s's 3 sample\n",
      "n7k5s's 4 sample\n",
      "n7k5s's 5 sample\n",
      "n7k5s's 6 sample\n",
      "n7k5s's 7 sample\n",
      "n7k5s's 8 sample\n",
      "n7k5s's 9 sample\n",
      "n7k5s's 10 sample\n",
      "n7k5d's 1 sample\n",
      "n7k5d's 2 sample\n",
      "n7k5d's 3 sample\n",
      "n7k5d's 4 sample\n",
      "n7k5d's 5 sample\n",
      "n7k5d's 6 sample\n",
      "n7k5d's 7 sample\n",
      "n7k5d's 8 sample\n",
      "n7k5d's 9 sample\n",
      "n7k5d's 10 sample\n",
      "n7k10s's 1 sample\n",
      "n7k10s's 2 sample\n",
      "n7k10s's 3 sample\n",
      "n7k10s's 4 sample\n",
      "n7k10s's 5 sample\n",
      "n7k10s's 6 sample\n",
      "n7k10s's 7 sample\n",
      "n7k10s's 8 sample\n",
      "n7k10s's 9 sample\n",
      "n7k10s's 10 sample\n",
      "n7k10d's 1 sample\n",
      "n7k10d's 2 sample\n",
      "n7k10d's 3 sample\n",
      "n7k10d's 4 sample\n",
      "n7k10d's 5 sample\n",
      "n7k10d's 6 sample\n",
      "n7k10d's 7 sample\n",
      "n7k10d's 8 sample\n",
      "n7k10d's 9 sample\n",
      "n7k10d's 10 sample\n",
      "n8k2s's 1 sample\n",
      "n8k2s's 2 sample\n",
      "n8k2s's 3 sample\n",
      "n8k2s's 4 sample\n",
      "n8k2s's 5 sample\n",
      "n8k2s's 6 sample\n",
      "n8k2s's 7 sample\n",
      "n8k2s's 8 sample\n",
      "n8k2s's 9 sample\n",
      "n8k2s's 10 sample\n",
      "n8k2d's 1 sample\n",
      "n8k2d's 2 sample\n",
      "n8k2d's 3 sample\n",
      "n8k2d's 4 sample\n",
      "n8k2d's 5 sample\n",
      "n8k2d's 6 sample\n",
      "n8k2d's 7 sample\n",
      "n8k2d's 8 sample\n",
      "n8k2d's 9 sample\n",
      "n8k2d's 10 sample\n",
      "n8k5s's 1 sample\n",
      "n8k5s's 2 sample\n"
     ]
    }
   ],
   "source": [
    "test_heuristics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38-6D1UywTv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
